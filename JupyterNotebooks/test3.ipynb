{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d51a5d00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f84e7686",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/cleaned_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7236ffab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>article</th>\n",
       "      <th>label</th>\n",
       "      <th>no_contract</th>\n",
       "      <th>article_str</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>lower</th>\n",
       "      <th>no_punc</th>\n",
       "      <th>stopwords_removed</th>\n",
       "      <th>pos_tags</th>\n",
       "      <th>wordnet_pos</th>\n",
       "      <th>lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>The president has yet to clarify what victory ...</td>\n",
       "      <td>right</td>\n",
       "      <td>['The', 'president', 'has', 'yet', 'to', 'clar...</td>\n",
       "      <td>The president has yet to clarify what victory ...</td>\n",
       "      <td>['The', 'president', 'has', 'yet', 'to', 'clar...</td>\n",
       "      <td>['the', 'president', 'has', 'yet', 'to', 'clar...</td>\n",
       "      <td>['the', 'president', 'has', 'yet', 'to', 'clar...</td>\n",
       "      <td>['president', 'yet', 'clarify', 'victory', 'pa...</td>\n",
       "      <td>[('president', 'NN'), ('yet', 'RB'), ('clarify...</td>\n",
       "      <td>[('president', 'n'), ('yet', 'r'), ('clarify',...</td>\n",
       "      <td>['president', 'yet', 'clarify', 'victory', 'pa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>To hear President Joe Biden tell it, the Amer...</td>\n",
       "      <td>right</td>\n",
       "      <td>['To', 'hear', 'President', 'Joe', 'Biden', 't...</td>\n",
       "      <td>To hear President Joe Biden tell it, the Ameri...</td>\n",
       "      <td>['To', 'hear', 'President', 'Joe', 'Biden', 't...</td>\n",
       "      <td>['to', 'hear', 'president', 'joe', 'biden', 't...</td>\n",
       "      <td>['to', 'hear', 'president', 'joe', 'biden', 't...</td>\n",
       "      <td>['hear', 'president', 'joe', 'biden', 'tell', ...</td>\n",
       "      <td>[('hear', 'JJ'), ('president', 'NN'), ('joe', ...</td>\n",
       "      <td>[('hear', 'a'), ('president', 'n'), ('joe', 'n...</td>\n",
       "      <td>['hear', 'president', 'joe', 'biden', 'tell', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>The mainstream media's honeymoon with Preside...</td>\n",
       "      <td>right</td>\n",
       "      <td>['The', 'mainstream', \"media's\", 'honeymoon', ...</td>\n",
       "      <td>The mainstream media's honeymoon with Presiden...</td>\n",
       "      <td>['The', 'mainstream', 'media', \"'s\", 'honeymoo...</td>\n",
       "      <td>['the', 'mainstream', 'media', \"'s\", 'honeymoo...</td>\n",
       "      <td>['the', 'mainstream', 'media', \"'s\", 'honeymoo...</td>\n",
       "      <td>['mainstream', 'media', \"'s\", 'honeymoon', 'pr...</td>\n",
       "      <td>[('mainstream', 'JJ'), ('media', 'NNS'), (\"'s\"...</td>\n",
       "      <td>[('mainstream', 'a'), ('media', 'n'), (\"'s\", '...</td>\n",
       "      <td>['mainstream', 'medium', \"'s\", 'honeymoon', 'p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>The \"Squad\" makes a demand for which there is ...</td>\n",
       "      <td>right</td>\n",
       "      <td>['The', '\"Squad\"', 'makes', 'a', 'demand', 'fo...</td>\n",
       "      <td>The \"Squad\" makes a demand for which there is ...</td>\n",
       "      <td>['The', '``', 'Squad', \"''\", 'makes', 'a', 'de...</td>\n",
       "      <td>['the', '``', 'squad', \"''\", 'makes', 'a', 'de...</td>\n",
       "      <td>['the', '``', 'squad', \"''\", 'makes', 'a', 'de...</td>\n",
       "      <td>['``', 'squad', \"''\", 'makes', 'demand', 'mili...</td>\n",
       "      <td>[('``', '``'), ('squad', 'NN'), (\"''\", \"''\"), ...</td>\n",
       "      <td>[('``', 'n'), ('squad', 'n'), (\"''\", 'n'), ('m...</td>\n",
       "      <td>['``', 'squad', \"''\", 'make', 'demand', 'milit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>The restraint crowd delivers America's humilia...</td>\n",
       "      <td>right</td>\n",
       "      <td>['The', 'restraint', 'crowd', 'delivers', \"Ame...</td>\n",
       "      <td>The restraint crowd delivers America's humilia...</td>\n",
       "      <td>['The', 'restraint', 'crowd', 'delivers', 'Ame...</td>\n",
       "      <td>['the', 'restraint', 'crowd', 'delivers', 'ame...</td>\n",
       "      <td>['the', 'restraint', 'crowd', 'delivers', 'ame...</td>\n",
       "      <td>['restraint', 'crowd', 'delivers', 'america', ...</td>\n",
       "      <td>[('restraint', 'NN'), ('crowd', 'NN'), ('deliv...</td>\n",
       "      <td>[('restraint', 'n'), ('crowd', 'n'), ('deliver...</td>\n",
       "      <td>['restraint', 'crowd', 'delivers', 'america', ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                            article  label  \\\n",
       "0           0  The president has yet to clarify what victory ...  right   \n",
       "1           1   To hear President Joe Biden tell it, the Amer...  right   \n",
       "2           2   The mainstream media's honeymoon with Preside...  right   \n",
       "3           3  The \"Squad\" makes a demand for which there is ...  right   \n",
       "4           4  The restraint crowd delivers America's humilia...  right   \n",
       "\n",
       "                                         no_contract  \\\n",
       "0  ['The', 'president', 'has', 'yet', 'to', 'clar...   \n",
       "1  ['To', 'hear', 'President', 'Joe', 'Biden', 't...   \n",
       "2  ['The', 'mainstream', \"media's\", 'honeymoon', ...   \n",
       "3  ['The', '\"Squad\"', 'makes', 'a', 'demand', 'fo...   \n",
       "4  ['The', 'restraint', 'crowd', 'delivers', \"Ame...   \n",
       "\n",
       "                                         article_str  \\\n",
       "0  The president has yet to clarify what victory ...   \n",
       "1  To hear President Joe Biden tell it, the Ameri...   \n",
       "2  The mainstream media's honeymoon with Presiden...   \n",
       "3  The \"Squad\" makes a demand for which there is ...   \n",
       "4  The restraint crowd delivers America's humilia...   \n",
       "\n",
       "                                           tokenized  \\\n",
       "0  ['The', 'president', 'has', 'yet', 'to', 'clar...   \n",
       "1  ['To', 'hear', 'President', 'Joe', 'Biden', 't...   \n",
       "2  ['The', 'mainstream', 'media', \"'s\", 'honeymoo...   \n",
       "3  ['The', '``', 'Squad', \"''\", 'makes', 'a', 'de...   \n",
       "4  ['The', 'restraint', 'crowd', 'delivers', 'Ame...   \n",
       "\n",
       "                                               lower  \\\n",
       "0  ['the', 'president', 'has', 'yet', 'to', 'clar...   \n",
       "1  ['to', 'hear', 'president', 'joe', 'biden', 't...   \n",
       "2  ['the', 'mainstream', 'media', \"'s\", 'honeymoo...   \n",
       "3  ['the', '``', 'squad', \"''\", 'makes', 'a', 'de...   \n",
       "4  ['the', 'restraint', 'crowd', 'delivers', 'ame...   \n",
       "\n",
       "                                             no_punc  \\\n",
       "0  ['the', 'president', 'has', 'yet', 'to', 'clar...   \n",
       "1  ['to', 'hear', 'president', 'joe', 'biden', 't...   \n",
       "2  ['the', 'mainstream', 'media', \"'s\", 'honeymoo...   \n",
       "3  ['the', '``', 'squad', \"''\", 'makes', 'a', 'de...   \n",
       "4  ['the', 'restraint', 'crowd', 'delivers', 'ame...   \n",
       "\n",
       "                                   stopwords_removed  \\\n",
       "0  ['president', 'yet', 'clarify', 'victory', 'pa...   \n",
       "1  ['hear', 'president', 'joe', 'biden', 'tell', ...   \n",
       "2  ['mainstream', 'media', \"'s\", 'honeymoon', 'pr...   \n",
       "3  ['``', 'squad', \"''\", 'makes', 'demand', 'mili...   \n",
       "4  ['restraint', 'crowd', 'delivers', 'america', ...   \n",
       "\n",
       "                                            pos_tags  \\\n",
       "0  [('president', 'NN'), ('yet', 'RB'), ('clarify...   \n",
       "1  [('hear', 'JJ'), ('president', 'NN'), ('joe', ...   \n",
       "2  [('mainstream', 'JJ'), ('media', 'NNS'), (\"'s\"...   \n",
       "3  [('``', '``'), ('squad', 'NN'), (\"''\", \"''\"), ...   \n",
       "4  [('restraint', 'NN'), ('crowd', 'NN'), ('deliv...   \n",
       "\n",
       "                                         wordnet_pos  \\\n",
       "0  [('president', 'n'), ('yet', 'r'), ('clarify',...   \n",
       "1  [('hear', 'a'), ('president', 'n'), ('joe', 'n...   \n",
       "2  [('mainstream', 'a'), ('media', 'n'), (\"'s\", '...   \n",
       "3  [('``', 'n'), ('squad', 'n'), (\"''\", 'n'), ('m...   \n",
       "4  [('restraint', 'n'), ('crowd', 'n'), ('deliver...   \n",
       "\n",
       "                                          lemmatized  \n",
       "0  ['president', 'yet', 'clarify', 'victory', 'pa...  \n",
       "1  ['hear', 'president', 'joe', 'biden', 'tell', ...  \n",
       "2  ['mainstream', 'medium', \"'s\", 'honeymoon', 'p...  \n",
       "3  ['``', 'squad', \"''\", 'make', 'demand', 'milit...  \n",
       "4  ['restraint', 'crowd', 'delivers', 'america', ...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "18673cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def modify(string):\n",
    "    string = string[1:-1]\n",
    "    for i in [\"'\",'\"',\"[\",\"]\",\",\",\"`\",\"â€™\"]:\n",
    "        string = string.replace(i,\"\")\n",
    "    return string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e0cca241",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = df.lemmatized,df.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e208f565",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X.apply(lambda x: modify(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4770594f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    president yet clarify victory pandemic look li...\n",
       "1    hear president joe biden tell american evacuat...\n",
       "2    mainstream medium s honeymoon president joe bi...\n",
       "3     squad  make demand military solution well par...\n",
       "4    restraint crowd delivers america s humiliation...\n",
       "Name: lemmatized, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "81962349",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f2d26a20",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ade47e65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2619, 27869)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_counts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "03a45794",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "62735f83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2619, 27869)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_tfidf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a8b50909",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB().fit(X_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d534f8d9",
   "metadata": {},
   "source": [
    "# BUILDING PIPELINE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "31f7e25a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2d424f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_clf = Pipeline([('vect', CountVectorizer()),\n",
    "                     ('tfidf', TfidfTransformer()),\n",
    "                     ('clf', MultinomialNB()),\n",
    "                    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7bef2834",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_clf = text_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1b1a42b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "preds = text_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c81314f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, f1_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4c3859a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_scores(clf, X_test, y_true):\n",
    "    y_preds = clf.predict(X_test)\n",
    "    print(\"*\"*50)\n",
    "    print(\"confusion matrix:\\n\", confusion_matrix(y_true, y_preds), \"\\n\")\n",
    "    print(\"*\"*50)\n",
    "    print(\"f1:\\n\", f1_score(y_true, y_preds, average='weighted'), \"\\n\")\n",
    "    print(\"*\"*50)\n",
    "    print(\"precision:\\n\", precision_score(y_true, y_preds, average='weighted'), \"\\n\")\n",
    "    print(\"*\"*50)\n",
    "    print(\"recall:\\n\", recall_score(y_true, y_preds, average='weighted'), \"\\n\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1d3f5946",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n",
      "confusion matrix:\n",
      " [[291   5  10]\n",
      " [ 60  99  60]\n",
      " [  0   2 346]] \n",
      "\n",
      "**************************************************\n",
      "f1:\n",
      " 0.8243920046894603 \n",
      "\n",
      "**************************************************\n",
      "precision:\n",
      " 0.8564402648724766 \n",
      "\n",
      "**************************************************\n",
      "recall:\n",
      " 0.843069873997709 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_scores(text_clf, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9ef1b103",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.843069873997709"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(preds == y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "55e9ea46",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bfcff909",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_clf_svm = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf_svm', SGDClassifier(loss='hinge',\n",
    "                              penalty='l2',\n",
    "                              alpha=1e-3,\n",
    "                              n_iter_no_change=5,\n",
    "                              n_jobs=-1,\n",
    "                              random_state=42)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1b066b1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9484536082474226"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_clf_svm = text_clf_svm.fit(X_train, y_train)\n",
    "preds = text_clf_svm.predict(X_test)\n",
    "np.mean(preds == y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "cec87752",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n",
      "confusion matrix:\n",
      " [[289  17   0]\n",
      " [  6 207   6]\n",
      " [  0  16 332]] \n",
      "\n",
      "**************************************************\n",
      "f1:\n",
      " 0.949207994709462 \n",
      "\n",
      "**************************************************\n",
      "precision:\n",
      " 0.9513015537153967 \n",
      "\n",
      "**************************************************\n",
      "recall:\n",
      " 0.9484536082474226 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_scores(text_clf_svm, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d700007d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "13ae0bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {\n",
    "    'vect__ngram_range': [(1,1),(1,2)],\n",
    "    'tfidf__use_idf': (True, False),\n",
    "    'clf__alpha': (1e-2, 1e-3),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "febd0b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_clf = GridSearchCV(text_clf, parameters, n_jobs=-1)\n",
    "gs_clf = gs_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e2e1b293",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9286040605432545"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_clf.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b9ce34c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'clf__alpha': 0.001, 'tfidf__use_idf': False, 'vect__ngram_range': (1, 2)}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1cd3582c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n",
      "confusion matrix:\n",
      " [[279  27   0]\n",
      " [ 13 206   0]\n",
      " [  0  21 327]] \n",
      "\n",
      "**************************************************\n",
      "f1:\n",
      " 0.9318006608757446 \n",
      "\n",
      "**************************************************\n",
      "precision:\n",
      " 0.9369884141547693 \n",
      "\n",
      "**************************************************\n",
      "recall:\n",
      " 0.9301260022909508 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_scores(gs_clf, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bafcfb3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
